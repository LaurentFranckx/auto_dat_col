}
TextToTest <- t(rbind(TextToTest,testword_vec))
TextToTest <- DfToSample[TextToSampleId  , ]
TextToTest <- TextToTest[, 2]
TextToTest
testword_vec <- character(length(TextToTest))
for(j in seq_along(length(TextToTest))){
splitstring <- strsplit(TextToTest[j], " ")[[1]]
stringlenth <- length(splitstring)
testword_vec[j] <- splitstring[stringlenth]
}
testword_vec
splitstring[stringlenth]
j
length(TextToTest)
testword_vec <- character(length(TextToTest))
for(j in seq_along(1:length(TextToTest))){
splitstring <- strsplit(TextToTest[j], " ")[[1]]
stringlenth <- length(splitstring)
testword_vec[j] <- splitstring[stringlenth]
}
testword_vec
TextToTest <- t(rbind(TextToTest,testword_vec))
TextToTest
colnames(TextToTest) <- c("first","V3")
TextToTest
CorpusUsedForTest <- TrainCorpus
TextToTest$first <- as.character(TextToTest$first)
TestResult <- sapply(TextToTest$first, function(x) SearchWrapper(x, CorpusUsedForTest, corpuslist, decrease = k), simplify = TRUE)
TrainCorpus <- "news"
CorpusUsedForTest <- TrainCorpus
TextToTest$first <- as.character(TextToTest$first)
TestResult <- sapply(TextToTest$first, function(x) SearchWrapper(x, CorpusUsedForTest, corpuslist, decrease = k), simplify = TRUE)
class(TextToTest)
TextToTest <- as.data.frame(TextToTest)
CorpusUsedForTest <- TrainCorpus
TextToTest$first <- as.character(TextToTest$first)
TestResult <- sapply(TextToTest$first, function(x) SearchWrapper(x, CorpusUsedForTest, corpuslist, decrease = k), simplify = TRUE)
load(file = "app1/data/corpuslist.RData")
getwd()
source('D:/coursera/dsc_capstone/testing_model.R', echo=TRUE)
?lineprof
devtools::install_github("hadley/lineprof")
library(lineprof)
lineprof
?lineprof
?shine
?stri_count_words
q()
?gc()
gcinfo(verbose)
getOption("verbose")
gcinfo(TRUE)
gc()
gcinfo(verbose)
getOption("verbose")
f3 <- function() {
x <- 1:1e6
function() 10
}
z <- f3()
z
ls(z)
environment(z)
environment(z)$x
f3 <- function() {
x <- 1:1e6
function() 10
}
z <- f3()
head(environment(z)$x)
tail(environment(z)$x)
z
shiny::runApp('D:/coursera/dsc_capstone/app2')
library(travelr)
q()
?rowMeans
?colMax
?apply
?close
(0.05*6+0.2*6+0.1*9+0.1*8+0.55*11)/11.2
(0.05*6+0.2*6+0.1*9+0.1*8+0.55*11)/11.2
?make
?quantile
q()
?aggregate
?join
plyr::join
?plyr::join
q()
?plot
q()
source('D:/rwebscraping/chap8exercises.r', echo=TRUE)
name
str_extract_all
?str_extract_all
names_split <- str_replace(names)
names_split <- lapply(names, str_replace)
names_split <- lapply(names, function(x) str_split(x, " "))
names_split
names_split <- sapply(names, function(x) str_split(x, " "))
names_split
str_extract_all(raw.data, "[[:alpha:]., ]{2,}")
str_extract_all(raw.data, "[[:alpha:]., ]{2,}")[[1]]
class(str_extract_all(raw.data, "[[:alpha:]., ]{2,}")[[1]]
)
names_split <- sapply(names_inter, function(x) str_split(x, " "))
names_inter<- str_extract_all(raw.data, "[[:alpha:]., ]{2,}")[[1]]
names_split <- sapply(names_inter, function(x) str_split(x, " "))
names_split
str_locate_all(names, "\\. ")
str_locate_all(name, "\\. ")
name
str_locate_all(name, "[[a-zA-Z]*{2,}\\. ")
str_locate_all(name, "[a-zA-Z]{2,}\\. ")
str_detect(name, "[a-zA-Z]{2,}\\. ")
str_detect(name, "[a-zA-Z]{2,}, ")
reverse_names <- name(str_detect(name, "[a-zA-Z]{2,}, "))
reverse_names <- name[str_detect(name, "[a-zA-Z]{2,}, ")]
reverse_names
reverse_names_split <- str_split(reverse_names, ", ")
reverse_names_split
reverse_names_split[[1]][1]
reverse_names_split[[1]][2]
lapply(reverse_names_split, function(x) str_c(x[2,],x[1,]))
lapply(reverse_names_split, function(x) str_c(x[2],x[1]))
?str_c
lapply(reverse_names_split, function(x) str_c(x[2],x[1], sep = " "))
sapply(reverse_names_split, function(x) str_c(x[2],x[1], sep = " "))
reverse_names_correct <- sapply(reverse_names_split, function(x) str_c(x[2],x[1], sep = " "))
reverse_names <- name[str_detect(name, "[a-zA-Z]{2,}, ")]
reverse_names_split <- str_split(reverse_names, ", ")
reverse_names_correct <- sapply(reverse_names_split, function(x) str_c(x[2],x[1], sep = " "))
name[reverse_names] <- reverse_names_correct
name
reverse_names_correct
reverse_names <- name[str_detect(name, "[a-zA-Z]{2,}, ")]
reverse_names_split <- str_split(reverse_names, ", ")
reverse_names_correct <- sapply(reverse_names_split, function(x) str_c(x[2],x[1], sep = " "))
name[reverse_names]
class(name[reverse_names])
name <- unlist(str_extract_all(raw.data, "[[:alpha:]., ]{2,}"))
name
name[reverse_names]
reverse_names
name[reverse_names]
reverse_names
reverse_names_pos <- str_detect(name, "[a-zA-Z]{2,}, ")
reverse_names <- name[reverse_names_pos]
reverse_names_split <- str_split(reverse_names, ", ")
reverse_names_correct <- sapply(reverse_names_split, function(x) str_c(x[2],x[1], sep = " "))
name[reverse_names] <- reverse_names_correct
name
reverse_names_pos <- str_detect(name, "[a-zA-Z]{2,}, ")
reverse_names <- name[reverse_names_pos]
reverse_names
reverse_names_pos <- str_detect(name, "[a-zA-Z]{2,}, ")
reverse_names <- name[reverse_names_pos]
reverse_names_split <- str_split(reverse_names, ", ")
reverse_names_correct <- sapply(reverse_names_split, function(x) str_c(x[2],x[1], sep = " "))
name[reverse_names_pos] <- reverse_names_correct
name
name <- unlist(str_extract_all(raw.data, "[[:alpha:]., ]{2,}"))
reverse_names_pos <- str_detect(name, "[a-zA-Z]{2,}, ")
reverse_names <- name[reverse_names_pos]
reverse_names_split <- str_split(reverse_names, ", ")
reverse_names_correct <- sapply(reverse_names_split, function(x) str_c(x[2],x[1], sep = " "))
name[reverse_names_pos] <- reverse_names_correct
name
str_detect(test_string1,"[0-9]+\\$")
test_string1 <- c("afhff2566","eedf25446eeer","ezzff4557$")
str_detect(test_string1,"[0-9]+\\$")
test_string2 <- c("afhff2566","eed", " edddg ", "ezzfffgfg")
str_detect(test_string2,"\\b[a-z]{1,4}\\b")
test_string2 <- c("afhff2566","eed", " ed ", "ezzfffgfg")
str_detect(test_string2,"\\b[a-z]{1,4}\\b")
test_string2 <- c("ag66","eed", " ed ", "ezzfffgfg")
str_detect(test_string2,"\\b[a-z]{1,4}\\b")
test_string3 <- c("file.text","file34.txt", "file.txt ", "   file.txt", ".txt")
str_detect(test_string3,".*?\\.txt")
test_string3 <- c("file.txt","file34.txt", "file.txt ", "   file.txt", ".txt")
str_detect(test_string3,".*?\\.txt$")
test_string3 <- c("122file.txt","file34.txt", "file.txt ", "   file.txt", ".txt")
str_detect(test_string3,".*?\\.txt$")
test_string4 <- c("22/32/4567","1234/45/4555555", "12/23354/2455")
str_detect(test_string4,"\\{2}/\\{2}/\\{4}")
test_string4 <- c("22/32/4567","1234/45/4555555", "12/23354/2455")
str_detect(test_string4,"\\d{2}/\\d{2}/\\d{4}")
test_string4 <- c("3222/32/4567","1234/45/4555555", "12/23354/2455")
str_detect(test_string4,"\\d{2}/\\d{2}/\\d{4}")
test_string5 <- c("<(112)>44445</5446112>","<()>44445</5446112>", "<(abc)>44445</54abc12>","<(112)>44445</5446abc>")
str_detect(test_string5,"<(.+?)>.+?</\\1>")
test_string5 <- c("<(112)>44445</<>","<()>44445</5446112>", "<(abc)>44445</54abc12>","<(112)>44445</5446abc>")
str_detect(test_string5,"<(.+?)>.+?</\\1>")
test_string5 <- c("<(112)>44445</<>","<112>44445</<>""<()>44445</5446112>", "<(abc)>44445</54abc12>","<(112)>44445</5446abc>")
str_detect(test_string5,"<(.+?)>.+?</\\1>")
test_string5 <- c("<(112)>44445</<>","<112>44445</<>","<()>44445</5446112>", "<(abc)>44445</54abc12>","<(112)>44445</5446abc>")
str_detect(test_string5,"<(.+?)>.+?</\\1>")
test_string5 <- c("<(112)>44445</<>","<112>44445</<>","<(abc)>44445</<>","<()>44445</5446112>", "<(abc)>44445</54abc12>","<(112)>44445</5446abc>")
str_detect(test_string5,"<(.+?)>.+?</\\1>")
test_string5 <- c("<(112)>44445</<>","<112>44445</<>","<(abc)>44445</<>","<()>44445</5446112>", "<(abc)>44445</54abc12>","<(112)>44445</5446abc>")
str_detect(test_string5,"<(.+?)>.+?</\\$1>")
test_string5 <- c("<(112)>44445</1>","<112>44445</<>","<(abc)>44445</<>","<()>44445</5446112>", "<(abc)>44445</54abc12>","<(112)>44445</5446abc>")
str_detect(test_string5,"<(.+?)>.+?</\\1>")
test_string5 <- c("<(112)>44445</112>","<112>44445</<>","<(abc)>44445</<>","<()>44445</5446112>", "<(abc)>44445</54abc12>","<(112)>44445</5446abc>")
str_detect(test_string5,"<(.+?)>.+?</\\1>")
test_string5 <- c("<(112)>4444515667</>","<112>44445</<>","<(abc)>44445</<>","<()>44445</5446112>", "<(abc)>44445</54abc12>","<(112)>44445</5446abc>")
str_detect(test_string5,"<(.+?)>.+?</\\1>")
test_string5 <- c("<(112)>444451125667</>","<112>44445</<>","<(abc)>44445</<>","<()>44445</5446112>", "<(abc)>44445</54abc12>","<(112)>44445</5446abc>")
str_detect(test_string5,"<(.+?)>.+?</\\1>")
str_extract("<(112)>444451125667</>","<(.+?)>.+?</\\1>")
str_extract("<(112)>445667</445112>","<(.+?)>.+?</\\1>")
str_extract("<(112)>4456671127789","<(.+?)>.+?\\1")
str_extract("<\\(112\\)>4456671127789\\(","<(.+?)>.+?\\1")
str_extract("<(112)>4456671127789","<(.+?)>.+?")
str_extract("<(112)>445667<","<(.+?)>.+?<")
str_extract("<(112)>445667</","<(.+?)>.+?</")
str_extract("<(112)>445667</","<(.+?)>.+?</\\1")
str_extract("<(112)>445667<</","<(.+?)>.+?</\\1")
str_extract("<(112)>445667112</","<(.+?)>.+?</\\1")
str_extract("<(112)>dfffg112</","<(.+?)>.+?</\\1")
str_extract("<(112)>dfffg112</","<(.+?)>.+?\\1")
str_extract("<(112)>dfffg(112)</","<(.+?)>.+?\\1")
str_extract("<(112)>dfffg(112)</","<(.+?)>.+?</\\1")
str_extract("<(112)>dff</fg(112)","<(.+?)>.+?</\\1")
str_extract("<(112)>dff</(112)","<(.+?)>.+?</\\1")
str_extract("<(112)>dff1225   44555</(112)","<(.+?)>.+?</\\1")
str_extract("<(112)>dff1225</44555</(112)","<(.+?)>.+?</\\1")
str_extract("<(112)>dff1225</44555</aahdddcg(112)","<(.+?)>.+?</\\1")
str_extract("<(112)>dff1225</44555</aahdddcg(112)/(112)","<(.+?)>.+?</\\1")
str_extract("<(112)>dff1225</44555</(112)/(112)","<(.+?)>.+?</\\1")
# load packages
library(stringr)
library(XML)
library(RCurl)
library(tau)
test_string1 <- c("afhff2566","eedf25446eeer","ezzff4557$")
str_detect(test_string1,"[0-9]+\\$")
str_detect(test_string1,"[[:digit:]]+\\$")
str_detect(test_string1,"[[:digit:]]{1,}\\$")
str_detect(test_string1,"[[:digit:]]{1,}[$]")
?str_replace
mailadres <- "chunkylover53[at]ao[dot]com"
str_replace(mailadres,"[at]","@")
mailadres
mailadres <- "chunkylover53[at]ao[dot]com"
str_replace(mailadres,"\\[at\\]","@")
mailadres <- "chunkylover53[at]ao[dot]com"
mailadres <- str_replace(mailadres,"\\[at\\]","@")
mailadres <- str_replace(mailadres,"\\[dot\\]","\\.")
mailadres
?str_extract
shopping_list <- c("apples x4", "flour", "sugar", "milk x2")
str_extract(shopping_list, "\\d")
str_extract_all(mailadres, "[:digit:]")
str_extract_all(mailadres, "\\d")
str_extract_all(mailadres, "[[:digit:]]")
str_extract_all(break_news, "<.+>")
break_news <- "<title>+++BREAKING NEWS++++</title>"
str_extract_all(break_news, "<.+>")
str_extract_all(break_news, "<.+?>")
str_extract(break_news, "<.+?>")
math_string <- "(5-3)^2 = 5^2 - 2*5*3 + 3^2 conforms to the the binomial theorem"
str_extract(math_string,"[^0-9=+*()]+")
str_extract_all(math_string,"[^0-9=+*()]+")
str_extract_all(math_string,"[0-9=+*()]+")
str_extract_all(math_string,"[0-9=+-*^()]+")
str_extract_all(math_string,"[0-9=+-*()]+")
math_string
str_extract_all(math_string,"[0-9=+-*()]+")
str_extract_all(math_string,"[0-9=+*()]+")
str_extract_all(math_string,"[0-9=+-*()]+")
str_extract_all(math_string,"[0-9=+*()]+")
str_extract_all(math_string,"[0-9=+*()]+-")
str_extract_all(math_string,"[0-9=+*()-]+")
str_extract_all(math_string,"[0-9=+*() -]+")
str_extract_all(math_string,"[0-9=+*()^ -]+")
str_extract_all(math_string,"[0-9=+*()^ -]+?")
str_extract_all(math_string,"[0-9=+*()^-]+")
str_extract_all(math_string,"[Ã¢-zA-Z0-9=+*()^-]+")
str_extract_all(math_string,"[^a-zA-Z0-9=+*()^-]+")
str_extract_all(math_string,"[^a-zA-Z]+")
str_extract(math_string,"[^a-zA-Z]+")
str_extract(math_string,"[0-9=+*()^-]+")
str_extract(math_string,"[0-9=+*()^- ]+")
str_extract(math_string,"[0-9=+*()^ -]+")
q()
### --------------------------------------------------------------
### AUTOMATED DATA COLLECTION WITH R
### SIMON MUNZERT, CHRISTIAN RUBBA, PETER MEISSNER, DOMINIC NYHUIS
###
### CODE CHAPTER 9: SCRAPING THE WEB
### --------------------------------------------------------------
# load packages
library(RCurl)
library(XML)
library(stringr)
library(plyr)
setwd("scenario-maryland")
# set local directory
setwd("D:/rwebscraping")
mkdir("scenario-maryland")
setwd("scenario-maryland")
?dir
?mdir
setwd("scenario-maryland")
u <- "http://www.elections.state.md.us/elections/2012/election_data/index.html"
page_parse <- htmlParse(u, encoding = "utf-8")
page_parse
links <- getHTMLLinks(u)
head(links)
filenames <- links[str_detect(links, "_General.csv")]
filenames
filenames_list <- as.list(filenames)
filenames_list
links
filenames_list[1:3]
u <- "http://www.elections.state.md.us/elections/2012/election_data/index.html"
page_parse <- htmlParse(u, encoding = "utf-8")
links <- getHTMLLinks(u)
filenames <- links[str_detect(links, "_General.csv")]
filenames_list <- as.list(filenames)
filenames_list[1:3]
# write download function
downloadCSV <- function(filename, baseurl, folder) {
dir.create(folder, showWarnings = FALSE)
fileurl <- str_c(baseurl, filename)
if (!file.exists(str_c(folder, "/", filename))) {
download.file(fileurl,
destfile = str_c(folder, "/", filename))
Sys.sleep(1)
}
}
# execute download
l_ply(filenames_list, downloadCSV,
baseurl = "http://www.elections.state.md.us/elections/2012/election_data/",
folder = "elec12_maryland")
# check results
length(list.files("./elec12_maryland"))
list.files("./elec12_maryland")[1:5]
url <- "http://planning.maryland.gov/Redistricting/2010/legiDist.shtml"
links <- getHTMLLinks(url)
filenames <- links[str_detect(links, "2010maps/Leg/Districts_")]
head(filenames)
filenames_list <- str_extract_all(filenames, "Districts.+pdf")
filenames_list[1:3]
?basename
basename(filenames)
?getBinaryURL
# write download function
downloadPDF <- function(filename, baseurl, folder, handle) {
dir.create(folder, showWarnings = FALSE)
fileurl <- str_c(baseurl, filename)
if (!file.exists(str_c(folder, "/", filename))) {
pdf_file <- getBinaryURL(fileurl, curl = handle)
writeBin(pdf_file, str_c(folder, "/", filename))
Sys.sleep(1)
}
}
# execute download
handle <- getCurlHandle()
handle <- getCurlHandle(useragent = str_c(R.version$platform, R.version$version.string, sep=", "), httpheader = c(from = "eddie@datacollection.com"))
l_ply(filenames_list, downloadPDF,
baseurl = "planning.maryland.gov/PDF/Redistricting/2010maps/Leg/",
folder = "elec12_maryland_maps",
handle = handle)
handle
l_ply(filenames_list, downloadPDF,
baseurl = "planning.maryland.gov/PDF/Redistricting/2010maps/Leg/",
folder = "elec12_maryland_maps",
handle = handle)
length(list.files("./elec12_maryland_maps"))
list.files("./elec12_maryland_maps")[1:5]
setwd("scenario-ftp")
mk.dir("scenario-ftp")
dir.create("scenario-ftp")
setwd("scenario-ftp")
ftp <- 'ftp://cran.r-project.org/pub/R/web/views/'
getHTMLLinks(ftp) # does not work
ftp_files <- getURL(ftp, dirlistonly = TRUE)
cat(ftp_files)
,getURL
?getURL
filenames <- strsplit(ftp_files, "\r\n")[[1]]
head(filenames)
filenames_html <- unlist(str_extract_all(filenames, ".+(.html)"))
head(filenames_html)
# write download function
downloadFTP <- function(filename, folder, handle) {
dir.create(folder, showWarnings = FALSE)
fileurl <- str_c(ftp, filename)
if (!file.exists(str_c(folder, "/", filename))) {
datafile <- try(getURL(fileurl, curl = handle))
write(datafile, str_c(folder, "/", filename))
Sys.sleep(1)
}
}
# execute download
handle <- getCurlHandle(ftp.use.epsv = FALSE)
l_ply(filenames_html, downloadFTP, folder = "cran_tasks", handle = handle)
l_ply(filenames_html, downloadFTP, folder = "cran_tasks", handle = handle)
setwd("D:/rwebscraping")
dir.create(("scenario-urlmanipulation"))
setwd("scenario-urlmanipulation")
ls()
baseurl <- htmlParse(url)
total_pages <- as.numeric(xpathSApply(baseurl, "//div[@id='Page']/strong[2]", xmlValue))
total_pages
url <- "http://www.transparency.org/news/pressreleases/year/2010"
baseurl <- htmlParse(url)
total_pages <- as.numeric(xpathSApply(baseurl, "//div[@id='Page']/strong[2]", xmlValue))
total_pages
max_url <- (total_pages - 1)*10
add_url <- str_c("/P", seq(10, max_url, 10))
urls_list <- as.list(str_c(url, add_url))
urls_list
url
# getPageURLs function
getPageURLs <- function(url) {
baseurl <- htmlParse(url)
total_pages <- as.numeric(xpathSApply(baseurl, "//div[@id='Page']/strong[2]", xmlValue))
max_url <- (total_pages - 1)*10
add_url <- str_c("/P", seq(10, max_url, 10))
urls_list <- as.list(str_c(url, add_url))
urls_list[length(urls_list) + 1] <- url
return(urls_list)
}
url <- "http://www.transparency.org/news/pressreleases/year/2010"
urls_list <- getPageURLs(url)
urls_list
# dlPages function
dlPages <- function(pageurl, folder ,handle) {
dir.create(folder, showWarnings = FALSE)
page_name <- str_c(str_extract(pageurl, "/P.+"), ".html")
if (page_name == "NA.html") { page_name <- "/base.html" }
if (!file.exists(str_c(folder, "/", page_name))) {
content <- try(getURL(pageurl, curl = handle))
write(content, str_c(folder, "/", page_name))
Sys.sleep(1)
}
}
handle <- getCurlHandle()
l_ply(urls_list, dlPages, folder = "tp_index_2010", handle = handle)
list.files("tp_index_2010")[1:3]
dir("tp_index_2010")
# dlPress function
dlPress <- function(press_url, folder, handle) {
dir.create(folder, showWarnings = FALSE)
press_filename <- str_c(str_extract(press_url, "[^//][[:alnum:]_.]+$") , ".html")
if (!file.exists(str_c(folder, "/", press_filename))) {
content <- try(getURL(press_url, curl = handle))
write(content, str_c(folder, "/", press_filename))
Sys.sleep(1)
}
}
handle <- getCurlHandle()
l_ply(press_urls_list, dlPress, folder = "tp_press_2010", handle = handle)
press_urls_list <- getPressURLs(folder = "tp_index_2010")
# dlPress function
dlPress <- function(press_url, folder, handle) {
dir.create(folder, showWarnings = FALSE)
press_filename <- str_c(str_extract(press_url, "[^//][[:alnum:]_.]+$") , ".html")
if (!file.exists(str_c(folder, "/", press_filename))) {
content <- try(getURL(press_url, curl = handle))
write(content, str_c(folder, "/", press_filename))
Sys.sleep(1)
}
}
handle <- getCurlHandle()
l_ply(press_urls_list, dlPress, folder = "tp_press_2010", handle = handle)
# getPressURLs function
getPressURLs <- function(folder) {
pages_parsed <- lapply(str_c(folder, "/", dir(folder)), htmlParse)
urls <- unlist(llply(pages_parsed, getHTMLLinks))
# urls <- unlist(llply(pages_parsed, xpathSApply, "//a/@href"))
press_urls <- urls[str_detect(urls, "http.+/pressrelease/")]
press_urls_list <- as.list(press_urls)
return(press_urls_list)
}
press_urls_list <- getPressURLs(folder = "tp_index_2010")
press_urls_list[1:3]
# dlPress function
dlPress <- function(press_url, folder, handle) {
dir.create(folder, showWarnings = FALSE)
press_filename <- str_c(str_extract(press_url, "[^//][[:alnum:]_.]+$") , ".html")
if (!file.exists(str_c(folder, "/", press_filename))) {
content <- try(getURL(press_url, curl = handle))
write(content, str_c(folder, "/", press_filename))
Sys.sleep(1)
}
}
handle <- getCurlHandle()
l_ply(press_urls_list, dlPress, folder = "tp_press_2010", handle = handle)
str_extract(press_urls_list[[1]], "[^//][[:alnum:]_.]+$")
str_extract(press_urls_list[[1]], "[^/][[:alnum:]_.]+$")
str_extract(press_urls_list[[1]], "[^///][[:alnum:]_.]+$")
str_extract(press_urls_list[[1]], "[^//][[:alnum:].]+$")
str_extract(press_urls_list[[1]], "[^//][[:alnum:]]+$")
str_extract(press_urls_list[[1]], "[^//][[:alnum:]_]+$")
str_extract(press_urls_list[[3]], "[^//][[:alnum:]]+$")
str_extract(press_urls_list[[3]], "[^//][[:alnum:]_]+$")
str_extract(press_urls_list[[3]], "[^//][[:alnum:].]+$")
str_extract(press_urls_list[[3]], "[^//][_[:alnum:].]+$")
?str_extract
str_extract(press_urls_list[[1]], "[^//][[:alnum:].]+$")
str_extract(press_urls_list[[1]], "[^//][[:alnum:]]+$")
str_extract(press_urls_list[[1]], "[^//][[:alnum:]_]+$")
str_extract(press_urls_list[[1]], "[^//][a-zA-Z_]+$")
str_extract(press_urls_list[[1]], "[a-zA-Z_]+$")
str_extract(press_urls_list[[1]], "[[:alnum:]_]+$")
str_extract(press_urls_list[[1]], "[[:alnum:]]+$")
q()
